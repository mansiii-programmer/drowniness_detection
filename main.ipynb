{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ab4357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758550671.240674   36879 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1758550671.244339   38090 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.2-arch1.2), renderer: Mesa Intel(R) Iris(R) Xe Graphics (TGL GT2)\n",
      "W0000 00:00:1758550671.246450   38085 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "from deepface import DeepFace\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n",
    "\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(static_image_mode=False,\n",
    "                             max_num_faces=10,\n",
    "                             refine_landmarks=True,\n",
    "                             min_detection_confidence=0.5)\n",
    "\n",
    "EAR_THRESH = 0.22       \n",
    "EAR_CONSEC_FRAMES = 15  \n",
    "\n",
    "\n",
    "LEFT_EYE  = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38484f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758550671.265709   38084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def calc_ear(landmarks, eye_idx, w, h):\n",
    "    pts = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in eye_idx]\n",
    "    A = dist.euclidean(pts[1], pts[5])\n",
    "    B = dist.euclidean(pts[2], pts[4])\n",
    "    C = dist.euclidean(pts[0], pts[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# -------------------- Tkinter GUI --------------------\n",
    "root = tk.Tk()\n",
    "root.title(\"Drowsiness Detection System\")\n",
    "root.geometry(\"1000x700\")\n",
    "\n",
    "panel = tk.Label(root)\n",
    "panel.pack()\n",
    "\n",
    "def analyze_frame(frame, counter_map):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        annotated_frame,\n",
    "        sleeping_count,\n",
    "        list_of_sleeping_ages\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    sleeping_count = 0\n",
    "    sleeping_ages = []\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        for idx, face in enumerate(result.multi_face_landmarks):\n",
    "            leftEAR = calc_ear(face.landmark, LEFT_EYE, w, h)\n",
    "            rightEAR = calc_ear(face.landmark, RIGHT_EYE, w, h)\n",
    "            ear_val = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            xs = [int(l.x * w) for l in face.landmark]\n",
    "            ys = [int(l.y * h) for l in face.landmark]\n",
    "            x1, y1, x2, y2 = min(xs), min(ys), max(xs), max(ys)\n",
    "\n",
    "            if idx not in counter_map:\n",
    "                counter_map[idx] = 0\n",
    "\n",
    "            if ear_val < EAR_THRESH:\n",
    "                counter_map[idx] += 1\n",
    "            else:\n",
    "                counter_map[idx] = 0\n",
    "\n",
    "            # Determine status\n",
    "            if counter_map[idx] >= EAR_CONSEC_FRAMES:\n",
    "                status = \"Sleeping\"\n",
    "                color = (0, 0, 255)\n",
    "                sleeping_count += 1\n",
    "\n",
    "                # Age prediction (do every ~30 frames to save time)\n",
    "                if counter_map[idx] % 30 == 0:\n",
    "                    try:\n",
    "                        crop = frame[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n",
    "                        pred = DeepFace.analyze(crop, actions=['age'],\n",
    "                                                enforce_detection=False)\n",
    "                        age_val = str(int(pred['age']))\n",
    "                        sleeping_ages.append(age_val)\n",
    "                    except:\n",
    "                        sleeping_ages.append(\"Unknown\")\n",
    "            else:\n",
    "                status = \"Awake\"\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, status, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    return frame, sleeping_count, sleeping_ages\n",
    "\n",
    "def show_popup(count, ages):\n",
    "    if count > 0:\n",
    "        messagebox.showinfo(\"Alert\",\n",
    "            f\"Sleeping People: {count}\\nAges: {', '.join(ages) if ages else 'Predicting...'}\")\n",
    "    else:\n",
    "        messagebox.showinfo(\"Info\", \"No one is sleeping.\")\n",
    "\n",
    "def process_image():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if not path:\n",
    "        return\n",
    "    img = cv2.imread(path)\n",
    "    img = imutils.resize(img, width=800)\n",
    "    counter_map = {}\n",
    "    processed, count, ages = analyze_frame(img, counter_map)\n",
    "    processed = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
    "    processed = ImageTk.PhotoImage(Image.fromarray(processed))\n",
    "    panel.configure(image=processed)\n",
    "    panel.image = processed\n",
    "    show_popup(count, ages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29751538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4 *.avi *.mov\")])\n",
    "    if not path:\n",
    "        return\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    counter_map = {}\n",
    "\n",
    "    def loop():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = imutils.resize(frame, width=800)\n",
    "            processed, count, ages = analyze_frame(frame, counter_map)\n",
    "            rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
    "            img = ImageTk.PhotoImage(Image.fromarray(rgb))\n",
    "            panel.configure(image=img)\n",
    "            panel.image = img\n",
    "            root.after(30, loop)\n",
    "            if count > 0:\n",
    "                show_popup(count, ages)\n",
    "        else:\n",
    "            cap.release()\n",
    "    loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a1fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_frame = tk.Frame(root)\n",
    "btn_frame.pack(pady=20)\n",
    "tk.Button(btn_frame, text=\"Process Image\", command=process_image,\n",
    "          bg=\"#4CAF50\", fg=\"white\", width=20).grid(row=0, column=0, padx=10)\n",
    "tk.Button(btn_frame, text=\"Process Video\", command=process_video,\n",
    "          bg=\"#2196F3\", fg=\"white\", width=20).grid(row=0, column=1, padx=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed40017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
